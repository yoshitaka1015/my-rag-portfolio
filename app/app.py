import streamlit as st
import numpy as np
import json
from google.cloud import storage
import vertexai
from vertexai.language_models import TextEmbeddingModel
from vertexai.generative_models import GenerativeModel
import os

# -----------------------------------------------------------------------------
# ç´”ç²‹é–¢æ•°ï¼ˆãƒ†ã‚¹ãƒˆã—ã‚„ã™ã„ã‚ˆã†ã«ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã«åˆ†é›¢ï¼‰
# -----------------------------------------------------------------------------

def find_similar_chunks(query_embedding, embeddings, texts, top_k=None):
    """ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã§é¡ä¼¼ãƒãƒ£ãƒ³ã‚¯ã‚’è¦‹ã¤ã‘ã‚‹ï¼ˆå®‰å…¨ãƒ»éç ´å£Šãƒ»ã‚·ãƒ³ãƒ—ãƒ«ï¼‰

    ä»•æ§˜:
      - å…¥åŠ›ã¯éç ´å£Šï¼ˆã‚³ãƒ”ãƒ¼ã—ã¦æ‰±ã†ï¼‰
      - å½¢çŠ¶ãŒä¸æ­£ãªã‚‰ ValueErrorï¼ˆE: 2æ¬¡å…ƒ, q: 1æ¬¡å…ƒ, è¡Œæ•°==ãƒ†ã‚­ã‚¹ãƒˆæ•°, åˆ—æ•°==ã‚¯ã‚¨ãƒªæ¬¡å…ƒï¼‰
      - ã‚³ãƒ¼ãƒ‘ã‚¹ãŒç©ºãªã‚‰ []
      - top_k æœªæŒ‡å®š(None) ã¯ 3 ä»¶ï¼ˆãŸã ã—ã‚³ãƒ¼ãƒ‘ã‚¹ä»¶æ•°ã‚’ä¸Šé™ï¼‰
      - top_k ãŒæ•´æ•°ã§ãªã„/0ä»¥ä¸‹ã¯ ValueError
      - NaN/Inf ã¯ 0 ã«ç½®æ›
      - ã‚¯ã‚¨ãƒªãŒã‚¼ãƒ­ãƒ™ã‚¯ãƒˆãƒ«ãªã‚‰ ValueError
      - ã‚³ãƒ¼ãƒ‘ã‚¹å´ã®ã‚¼ãƒ­ãƒ™ã‚¯ãƒˆãƒ«ã¯é¡ä¼¼åº¦ 0 ã¨ã¿ãªã™
    """
    import numpy as np

    # éç ´å£Šã‚³ãƒ”ãƒ¼
    q = np.array(query_embedding, dtype=float, copy=True)
    E = np.array(embeddings, dtype=float, copy=True)
    T = list(texts)

    # å½¢çŠ¶ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆ1è¡Œã§é›†ç´„ï¼‰
    if not (E.ndim == 2 and q.ndim == 1 and E.shape[0] == len(T) and E.shape[1] == q.shape[0]):
        raise ValueError("invalid shapes")

    # ç©ºã‚³ãƒ¼ãƒ‘ã‚¹ã¯ç©ºé…åˆ—ã‚’è¿”ã™
    if len(T) == 0:
        return []

    # top_k ã®æ±ºå®š
    if top_k is None:
        k = min(3, len(T))
    else:
        try:
            k = int(top_k)
        except (TypeError, ValueError):
            raise ValueError("top_k must be an integer")
        if k <= 0:
            raise ValueError("top_k must be >= 1")
        k = min(k, len(T))

    # NaN/Inf ã‚’ 0 ã«æ­£è¦åŒ–
    q = np.nan_to_num(q, nan=0.0, posinf=0.0, neginf=0.0)
    E = np.nan_to_num(E, nan=0.0, posinf=0.0, neginf=0.0)

    # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—ï¼ˆã‚¼ãƒ­å‰²/ã‚¼ãƒ­ãƒãƒ«ãƒ å¯¾ç­–ï¼‰
    qnorm = np.linalg.norm(q)
    if qnorm == 0.0:
        raise ValueError("query embedding has zero norm")

    Enorms = np.linalg.norm(E, axis=1)
    denom = Enorms * qnorm
    denom_safe = np.where(denom == 0.0, 1.0, denom)
    sims = (E @ q) / denom_safe
    sims = np.where(Enorms == 0.0, 0.0, sims)

    top_idx = np.argsort(-sims)[:k]
    return [T[i] for i in top_idx]


def build_prompt(query: str, similar_chunks: list[str]) -> str:
    """å›ç­”ç”Ÿæˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œã‚‹ç´”ç²‹é–¢æ•°"""
    context = "\n---\n".join(similar_chunks)
    return f"""
ä»¥ä¸‹ã®æƒ…å ±ã‚’å‚è€ƒã«ã—ã¦ã€è³ªå•ã«æ—¥æœ¬èªã§è©³ã—ãå›ç­”ã—ã¦ãã ã•ã„ã€‚

--- æƒ…å ± ---
{context}
--- æƒ…å ±çµ‚ã‚ã‚Š ---

è³ªå•: {query}
""".strip()


def generate_answer(generative_model: GenerativeModel, prompt: str) -> str:
    """LLMã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ¸¡ã—ã¦å›ç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™ç´”ç²‹é–¢æ•°"""
    resp = generative_model.generate_content([prompt])
    return getattr(resp, "text", "").strip()

# -----------------------------------------------------------------------------
# Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯
# -----------------------------------------------------------------------------
def main():
    """
    Streamlitã‚¢ãƒ—ãƒªã®ãƒ¡ã‚¤ãƒ³é–¢æ•°ã€‚
    GCPã¸ã®æ¥ç¶šã‚„UIã®æç”»ãªã©ã€å‰¯ä½œç”¨ã®ã‚ã‚‹å‡¦ç†ã¯ã™ã¹ã¦ã“ã®ä¸­ã«è¨˜è¿°ã—ã¾ã™ã€‚
    """
    # --- 1. å®šæ•°ã¨è¨­å®š ---
    PROJECT_ID = os.environ.get("GCP_PROJECT", "serious-timer-467517-e1")
    REGION = os.environ.get("REGION", "us-central1")
    VECTOR_BUCKET_NAME = os.environ.get("VECTOR_BUCKET_NAME")
    EMBEDDING_MODEL_NAME = "text-embedding-004"
    LLM_MODEL_NAME = "gemini-1.5-pro"  # å®‰å®šç‰ˆ

    # --- 2. ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ– ---
    try:
        vertexai.init(project=PROJECT_ID, location=REGION)
        storage_client = storage.Client()
        embedding_model = TextEmbeddingModel.from_pretrained(EMBEDDING_MODEL_NAME)
        generative_model = GenerativeModel(LLM_MODEL_NAME)
    except Exception as e:
        st.error(f"GCPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return

    # --- 3. ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ï¼ˆãƒã‚¹ãƒˆ: è¦ªã‚¹ã‚³ãƒ¼ãƒ—ã®ä¾å­˜ã‚’ãã®ã¾ã¾ä½¿ã†ï¼‰ ---
    @st.cache_data(show_spinner=False)
    def load_vectors_from_gcs():
        """GCSã‹ã‚‰å…¨ã¦ã®JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ãƒ™ã‚¯ãƒˆãƒ«ã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹"""
        if not VECTOR_BUCKET_NAME:
            st.error("ç’°å¢ƒå¤‰æ•° VECTOR_BUCKET_NAME ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return None, None

        bucket = storage_client.bucket(VECTOR_BUCKET_NAME)
        blobs = list(bucket.list_blobs())

        if not blobs:
            return None, None

        all_chunks = []
        for blob in blobs:
            if blob.name.endswith(".jsonl"):
                content = blob.download_as_text()
                for line in content.strip().split("\n"):
                    if line:
                        all_chunks.append(json.loads(line))

        if not all_chunks:
            return None, None

        texts = [c["text_content"] for c in all_chunks]
        embeddings = np.array([c["embedding"] for c in all_chunks], dtype=float)
        embeddings = np.nan_to_num(embeddings, nan=0.0, posinf=0.0, neginf=0.0)
        return texts, embeddings

    # --- 4. UI ---
    st.set_page_config(page_title="RAG Portfolio", layout="wide")
    st.title("RAGã‚·ã‚¹ãƒ†ãƒ  ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª")

    with st.spinner("GCSã‹ã‚‰çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
        texts, embeddings = load_vectors_from_gcs()

    if embeddings is None:
        st.error("GCSãƒã‚±ãƒƒãƒˆã«ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Cloud Functionã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‡¦ç†ã—ã¦ãã ã•ã„ã€‚")
        return

    st.success(f"{len(texts)}å€‹ã®ãƒŠãƒ¬ãƒƒã‚¸ãƒãƒ£ãƒ³ã‚¯ã‚’GCSã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")

    query = st.text_input("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«é–¢ã™ã‚‹è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", key="query_input")
    if st.button("è³ªå•ã™ã‚‹", key="submit_button"):
        if not query:
            st.error("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return

        with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­ã§ã™..."):
            try:
                # åŸ‹ã‚è¾¼ã¿ç”Ÿæˆï¼ˆNaN/Infã‚’0ã«ï¼‰
                q_emb = embedding_model.get_embeddings([query])[0].values
                q_emb = np.array(q_emb, dtype=float)
                q_emb = np.nan_to_num(q_emb, nan=0.0, posinf=0.0, neginf=0.0)

                # é¡ä¼¼ãƒãƒ£ãƒ³ã‚¯æŠ½å‡ºï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3ä»¶ï¼‰
                similar = find_similar_chunks(q_emb, embeddings, texts, top_k=None)

                # å›ç­”ç”Ÿæˆ
                prompt = build_prompt(query, similar)
                answer = generate_answer(generative_model, prompt)

                st.subheader("ğŸ¤– å›ç­”:")
                st.write(answer or "(ç©ºã®å¿œç­”)")

                with st.expander("AIãŒå‚è€ƒã«ã—ãŸæƒ…å ±æºã‚’è¡¨ç¤º"):
                    for chunk in similar:
                        st.info(chunk)

            except ValueError as ve:
                # ä¾‹: top_k < 0 / ã‚¯ã‚¨ãƒªã‚¼ãƒ­ãƒ™ã‚¯ãƒˆãƒ«ç­‰
                st.error(f"å…¥åŠ›ã‚¨ãƒ©ãƒ¼: {ve}")
            except Exception as e:
                st.error(f"å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒ "streamlit run app.py" ã§ç›´æ¥å®Ÿè¡Œã•ã‚ŒãŸæ™‚ã ã‘ã€main()é–¢æ•°ã‚’å‘¼ã³å‡ºã™
if __name__ == "__main__":
    main()