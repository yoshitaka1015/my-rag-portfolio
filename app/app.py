import streamlit as st
import numpy as np
import json
from google.cloud import storage
import vertexai
from vertexai.language_models import TextEmbeddingModel
from vertexai.generative_models import GenerativeModel
import os

# -----------------------------------------------------------------------------
# ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆå¯¾è±¡ã®ç´”ç²‹ãªé–¢æ•°
# (ã“ã®é–¢æ•°ã¯GCPã«æ¥ç¶šã—ãªã„ãŸã‚ã€å®‰å…¨ã«ãƒ†ã‚¹ãƒˆã§ãã¾ã™)
# -----------------------------------------------------------------------------
def find_similar_chunks(query_embedding, embeddings, texts, top_k=5):
    """ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã§æœ€ã‚‚é¡ä¼¼ã—ãŸãƒãƒ£ãƒ³ã‚¯ã‚’è¦‹ã¤ã‘ã‚‹"""
    # Numpyã§ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—
    dot_products = np.dot(embeddings, query_embedding)
    norms = np.linalg.norm(embeddings, axis=1) * np.linalg.norm(query_embedding)
    similarities = dot_products / norms
    
    # é¡ä¼¼åº¦ãŒé«˜ã„é †ã«ã‚½ãƒ¼ãƒˆã—ã€ãƒˆãƒƒãƒ—Kã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
    top_k_indices = np.argsort(similarities)[-top_k:][::-1]
    
    return [texts[i] for i in top_k_indices]


# -----------------------------------------------------------------------------
# Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯
# -----------------------------------------------------------------------------
def main():
    """
    Streamlitã‚¢ãƒ—ãƒªã®ãƒ¡ã‚¤ãƒ³é–¢æ•°ã€‚
    GCPã¸ã®æ¥ç¶šã‚„UIã®æç”»ãªã©ã€å‰¯ä½œç”¨ã®ã‚ã‚‹å‡¦ç†ã¯ã™ã¹ã¦ã“ã®ä¸­ã«è¨˜è¿°ã—ã¾ã™ã€‚
    """
    # --- 1. å®šæ•°ã¨è¨­å®š ---
    PROJECT_ID = "serious-timer-467517-e1"
    REGION = "asia-northeast1"
    VECTOR_BUCKET_NAME = os.environ.get("VECTOR_BUCKET_NAME")
    EMBEDDING_MODEL_NAME = "text-embedding-004"
    LLM_MODEL_NAME = "gemini-1.5-pro" # æœ€æ–°ã®å®‰å®šç‰ˆãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨

    # --- 2. ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ– ---
    try:
        vertexai.init(project=PROJECT_ID, location=REGION)
        storage_client = storage.Client()
        embedding_model = TextEmbeddingModel.from_pretrained(EMBEDDING_MODEL_NAME)
        generative_model = GenerativeModel(LLM_MODEL_NAME)
    except Exception as e:
        st.error(f"GCPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return

    # --- é–¢æ•°ã®å®šç¾© ---
    # @st.cache_dataã¯ã€ä¸€åº¦èª­ã¿è¾¼ã‚“ã GCSã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦ã‚¢ãƒ—ãƒªã‚’é«˜é€ŸåŒ–ã—ã¾ã™
    @st.cache_data(show_spinner=False)
    def load_vectors_from_gcs():
        """GCSã‹ã‚‰å…¨ã¦ã®JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ãƒ™ã‚¯ãƒˆãƒ«ã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹"""
        if not VECTOR_BUCKET_NAME:
            st.error("ç’°å¢ƒå¤‰æ•° VECTOR_BUCKET_NAME ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return None, None

        bucket = storage_client.bucket(VECTOR_BUCKET_NAME)
        blobs = list(bucket.list_blobs())
        
        if not blobs:
            return None, None
            
        all_chunks = []
        for blob in blobs:
            if blob.name.endswith('.jsonl'):
                content = blob.download_as_text()
                for line in content.strip().split('\n'):
                    if line:
                        all_chunks.append(json.loads(line))
        
        if not all_chunks:
            return None, None
            
        texts = [chunk['text_content'] for chunk in all_chunks]
        embeddings = np.array([chunk['embedding'] for chunk in all_chunks])
        
        return texts, embeddings

    def generate_answer(query, similar_chunks):
        """LLMã‚’ä½¿ã£ã¦å›ç­”ã‚’ç”Ÿæˆã™ã‚‹"""
        context = "\n---\n".join(similar_chunks)
        prompt = f"""
        ä»¥ä¸‹ã®æƒ…å ±ã‚’å‚è€ƒã«ã—ã¦ã€è³ªå•ã«æ—¥æœ¬èªã§è©³ã—ãå›ç­”ã—ã¦ãã ã•ã„ã€‚

        --- æƒ…å ± ---
        {context}
        --- æƒ…å ±çµ‚ã‚ã‚Š ---

        è³ªå•: {query}
        """
        response = generative_model.generate_content([prompt])
        return response.text

    # --- 3. Streamlit UI ---
    st.set_page_config(page_title="RAG Portfolio", layout="wide")
    st.title("RAGã‚·ã‚¹ãƒ†ãƒ  ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª")

    with st.spinner("GCSã‹ã‚‰çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
        texts, embeddings = load_vectors_from_gcs()

    if embeddings is None:
        st.error("GCSãƒã‚±ãƒƒãƒˆã«ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Cloud Functionã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‡¦ç†ã—ã¦ãã ã•ã„ã€‚")
    else:
        st.success(f"{len(texts)}å€‹ã®ãƒŠãƒ¬ãƒƒã‚¸ãƒãƒ£ãƒ³ã‚¯ã‚’GCSã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")
        query = st.text_input("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«é–¢ã™ã‚‹è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", key="query_input")

        if st.button("è³ªå•ã™ã‚‹", key="submit_button"):
            if query:
                with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­ã§ã™..."):
                    query_embedding = embedding_model.get_embeddings([query])[0].values
                    similar_chunks = find_similar_chunks(query_embedding, embeddings, texts)
                    answer = generate_answer(query, similar_chunks)
                    
                    st.subheader("ğŸ¤– å›ç­”:")
                    st.write(answer)

                    with st.expander("AIãŒå‚è€ƒã«ã—ãŸæƒ…å ±æºã‚’è¡¨ç¤º"):
                        for chunk in similar_chunks:
                            st.info(chunk)
            else:
                st.error("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

# ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒ "streamlit run app.py" ã§ç›´æ¥å®Ÿè¡Œã•ã‚ŒãŸæ™‚ã ã‘ã€main()é–¢æ•°ã‚’å‘¼ã³å‡ºã™
if __name__ == "__main__":
    main()